# Pipeline 02 ETL - Desvio de Carregamento

Pipeline ETL especializado para processamento de dados de Desvio de Carregamento (Pipeline 02) no sistema Conecta Boi.

## ğŸ¯ Objetivo

Este pipeline processa dados CSV de desvio de carregamento de raÃ§Ã£o, aplicando validaÃ§Ãµes de negÃ³cio, limpeza de dados e cÃ¡lculos de desvio antes de inserir/atualizar na tabela fato `fato_desvio_carregamento`.

## ğŸ“‹ Funcionalidades

### âœ… ValidaÃ§Ã£o de Dados
- **Equipamentos vÃ¡lidos**: Apenas BAHMAN e SILOKING
- **Datas**: Rejeita datas futuras, suporte a formato brasileiro DD/MM/YYYY
- **Valores numÃ©ricos**: Rejeita valores negativos, suporte a formato brasileiro (vÃ­rgula decimal)
- **Campos obrigatÃ³rios**: ValidaÃ§Ã£o de campos essenciais

### ğŸ§¹ Limpeza de Dados
- **NormalizaÃ§Ã£o de equipamentos**: BAHMANN â†’ BAHMAN, SILO KING â†’ SILOKING
- **FormataÃ§Ã£o de datas**: DD/MM/YYYY â†’ Date
- **FormataÃ§Ã£o numÃ©rica**: 1.250,50 â†’ 1250.5
- **Limpeza de texto**: Trim, normalizaÃ§Ã£o de caracteres

### ğŸ“Š CÃ¡lculos de NegÃ³cio
- **Desvio em KG**: kg_real - kg_planejado
- **Desvio percentual**: (desvio_kg / kg_planejado) Ã— 100
- **Chave natural**: GeraÃ§Ã£o automÃ¡tica para operaÃ§Ãµes idempotentes

### ğŸ”„ UPSERT Idempotente
- **DetecÃ§Ã£o de mudanÃ§as**: Compara dados existentes antes de atualizar
- **EstratÃ©gias mÃºltiplas**: Single record, batch, PostgreSQL nativo
- **Lookup de dimensÃµes**: IntegraÃ§Ã£o com tabelas de dimensÃ£o

## ğŸš€ Uso RÃ¡pido

```typescript
import { processDesvioCarregamentoCSV } from '@conecta-boi/pipeline02-etl';

const result = await processDesvioCarregamentoCSV(
  csvContent,
  'org-123',
  'file-456',
  'postgresql://localhost:5432/db',
  {
    batchSize: 1000,
    skipValidation: false,
    environment: 'production'
  }
);

console.log(`Processadas: ${result.totalRows} linhas`);
console.log(`VÃ¡lidas: ${result.validRows}, InvÃ¡lidas: ${result.invalidRows}`);
```

## ğŸ”§ Uso AvanÃ§ado

```typescript
import {
  Pipeline02ETLProcessor,
  Pipeline02BusinessValidator,
  Pipeline02DataCleanser,
  createPipeline02Config,
  PIPELINE02_PRESETS
} from '@conecta-boi/pipeline02-etl';

// ConfiguraÃ§Ã£o personalizada
const config = createPipeline02Config('production', {
  processing: {
    batchSize: 5000,
    maxRetries: 3
  },
  validation: {
    strictMode: true,
    maxDeviationPercent: 50
  }
});

// Ou usar preset
const processor = new Pipeline02ETLProcessor({
  ...PIPELINE02_PRESETS.HIGH_THROUGHPUT,
  connectionString: process.env.DATABASE_URL,
  organizationId: 'org-123',
  fileId: 'file-456'
});

const result = await processor.processCSVFile(csvContent);
```

## ğŸ“Š Formato CSV Esperado

```csv
Data,Turno,Equipamento,Curral,Dieta,Kg Planejado,Kg Real
15/01/2024,MANHÃƒ,BAHMAN,CUR-001,Dieta A,"1.000,50","980,25"
15/01/2024,TARDE,SILOKING,CUR-002,Dieta B,"1.500,00","1.520,75"
16/01/2024,MANHÃƒ,BAHMAN,CUR-003,,"850,25","830,00"
```

### Campos ObrigatÃ³rios
- **Data**: DD/MM/YYYY (nÃ£o pode ser futura)
- **Turno**: MANHÃƒ, TARDE, NOITE
- **Equipamento**: BAHMAN ou SILOKING
- **Curral**: CÃ³digo do curral
- **Kg Planejado**: Valor numÃ©rico positivo
- **Kg Real**: Valor numÃ©rico positivo

### Campos Opcionais
- **Dieta**: Nome da dieta (pode ser vazio)

## ğŸ—ï¸ Arquitetura

### Componentes Principais

```
Pipeline02ETLProcessor
â”œâ”€â”€ Pipeline02DataCleanser          # Limpeza e normalizaÃ§Ã£o
â”œâ”€â”€ Pipeline02BusinessValidator     # ValidaÃ§Ã£o de regras de negÃ³cio
â”œâ”€â”€ FactTableUpsertService          # OperaÃ§Ãµes UPSERT idempotentes
â””â”€â”€ DimensionLookupService          # Lookup de IDs de dimensÃ£o
```

### Fluxo de Processamento

1. **Parse CSV** â†’ Headers e linhas
2. **Limpeza** â†’ NormalizaÃ§Ã£o de dados
3. **ValidaÃ§Ã£o** â†’ Regras de negÃ³cio
4. **CÃ¡lculos** â†’ Desvios e chave natural
5. **Staging** â†’ InserÃ§Ã£o na tabela de staging
6. **UPSERT** â†’ InserÃ§Ã£o/atualizaÃ§Ã£o idempotente na tabela fato

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
DATABASE_URL=postgresql://localhost:5432/conectaboi
NODE_ENV=production
```

### ConfiguraÃ§Ãµes por Ambiente

- **Development**: Batch size 100, logging habilitado, validaÃ§Ã£o flexÃ­vel
- **Testing**: Batch size 10, logging desabilitado, validaÃ§Ã£o relaxada
- **Staging**: Batch size 500, validaÃ§Ã£o rigorosa
- **Production**: Batch size 2000, paralelizaÃ§Ã£o habilitada, validaÃ§Ã£o rigorosa

## ğŸ§ª Testes

```bash
# Executar todos os testes
npm test

# Executar testes especÃ­ficos
npm run test:business-rules
npm run test:data-cleanser
npm run test:upsert-logic
npm run test:deviation-calculations
```

### Cobertura de Testes

- âœ… **Business Rules**: 8 testes (validaÃ§Ã£o, cÃ¡lculos, chave natural)
- âœ… **Data Cleanser**: 7 testes (limpeza, normalizaÃ§Ã£o, formataÃ§Ã£o)
- âœ… **UPSERT Logic**: 7 testes (inserÃ§Ã£o, atualizaÃ§Ã£o, skip, batch)
- âœ… **Deviation Calculations**: 8 testes (cÃ¡lculos, precisÃ£o, formatos)

## ğŸ“ˆ Performance

### Benchmarks

- **Throughput**: ~1000 linhas/segundo (modo padrÃ£o)
- **Throughput Alto**: ~2000+ linhas/segundo (preset HIGH_THROUGHPUT)
- **MemÃ³ria**: ~50MB para 10.000 linhas (batch size 1000)

### OtimizaÃ§Ãµes

- **Batch Processing**: Processa em lotes para reduzir overhead
- **Connection Pooling**: ReutilizaÃ§Ã£o de conexÃµes de banco
- **ValidaÃ§Ã£o Eficiente**: Zod v3.x para validaÃ§Ã£o rÃ¡pida
- **UPSERT Nativo**: PostgreSQL ON CONFLICT para mÃ¡xima performance

## ğŸ”— IntegraÃ§Ã£o

### Sistema Principal

```typescript
// Em um Supabase Edge Function
import { processDesvioCarregamentoCSV } from '@conecta-boi/pipeline02-etl';

export default async function handler(req: Request) {
  const { csvContent, organizationId, fileId } = await req.json();

  const result = await processDesvioCarregamentoCSV(
    csvContent,
    organizationId,
    fileId,
    Deno.env.get('DATABASE_URL')!,
    { environment: 'production' }
  );

  return new Response(JSON.stringify(result));
}
```

### Monitoramento

```typescript
const result = await processor.processCSVFile(csvContent);

// Log de sucesso
console.log(`ETL Pipeline 02 - Sucesso: ${result.success}`);
console.log(`Processadas: ${result.totalRows} linhas em ${result.duration}ms`);
console.log(`Taxa de sucesso: ${(result.validRows/result.totalRows*100).toFixed(1)}%`);

// Alertas para alta taxa de erro
if (result.invalidRows / result.totalRows > 0.1) {
  console.warn(`Alta taxa de erro: ${(result.invalidRows/result.totalRows*100).toFixed(1)}%`);
}
```

## ğŸš¨ Tratamento de Erros

### Categorias de Erros

- **Parsing**: Problemas na estrutura do CSV
- **Cleansing**: Dados que nÃ£o puderam ser limpos
- **Validation**: ViolaÃ§Ã£o de regras de negÃ³cio
- **Staging**: Falhas na inserÃ§Ã£o em staging
- **Fact Table**: Falhas no UPSERT da tabela fato

### EstratÃ©gias de RecuperaÃ§Ã£o

- **Retry AutomÃ¡tico**: AtÃ© 3 tentativas para erros temporÃ¡rios
- **Rollback**: TransaÃ§Ãµes sÃ£o revertidas em caso de falha
- **Logging Detalhado**: Logs estruturados para debugging
- **Graceful Degradation**: Processamento continua mesmo com erros individuais

## ğŸ“š Exemplos Completos

Ver arquivos na pasta `src/examples/`:
- `pipeline-usage.ts`: Uso bÃ¡sico e demonstraÃ§Ãµes
- `error-handling.ts`: Tratamento de erros
- `performance.ts`: Testes de performance

## ğŸ” Debugging

### Logs Detalhados

```typescript
const processor = new Pipeline02ETLProcessor({
  // ... config
  enableLogging: true
});

// Logs automÃ¡ticos em cada etapa
// [INFO] ETL_START: Iniciando processamento ETL Pipeline 02
// [INFO] CSV_PARSED: CSV processado: 1000 linhas
// [INFO] BATCH_PROCESSED: Batch processado: 1-100
// [INFO] FACT_UPSERT: Record updated
// [INFO] ETL_COMPLETE: Processamento ETL concluÃ­do
```

### AnÃ¡lise de Erros

```typescript
if (!result.success) {
  console.log('AnÃ¡lise de Erros:');

  const errorsByStage = result.errors.reduce((acc, error) => {
    acc[error.stage] = (acc[error.stage] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  console.table(errorsByStage);
}
```

## ğŸ› ï¸ Desenvolvimento

### Setup Local

```bash
cd packages/pipeline02-etl
npm install
npm run build
npm test
```

### Estrutura de Arquivos

```
src/
â”œâ”€â”€ validators/           # ValidaÃ§Ã£o e limpeza de dados
â”‚   â”œâ”€â”€ business-rules.ts
â”‚   â””â”€â”€ data-cleanser.ts
â”œâ”€â”€ services/            # ServiÃ§os de negÃ³cio
â”‚   â”œâ”€â”€ upsert-strategy.ts
â”‚   â””â”€â”€ dimension-lookup.ts
â”œâ”€â”€ config/              # ConfiguraÃ§Ãµes
â”‚   â””â”€â”€ pipeline-config.ts
â”œâ”€â”€ test/                # Testes unitÃ¡rios
â”œâ”€â”€ examples/            # Exemplos de uso
â””â”€â”€ index.ts            # Ponto de entrada principal
```

## ğŸ“„ LicenÃ§a

MIT - Ver LICENSE file para detalhes.